# Standard Library
from os import listdir
from os.path import isfile, join
from pathlib import Path

# Third Party
from linkml_runtime.dumpers import YAMLDumper
from pydantic import BaseModel
from sssom.parsers import parse_sssom_table

# Local
try:
    # allow duplicates
    from {{ project_slug }}_pydantic import PersonCollection, Person
except ImportError:
    # disallow duplicates
    from {{ project_slug }} import PersonCollection, Person
from {{ project_slug }}.toolkit.logging import configure_logger


MAP_DIR = "src/{{ project_slug }}/data/mappings/"
DATA_DIR = "src/{{ project_slug }}/data/knowledge_graph/mappings/"

logger = configure_logger(__name__)


class PersonMap(BaseModel):
    src_person_id: str
    target_person_id: str
    relationship: str

    def __init__(self, src_person_id: str, target_person_id: str, relationship: str):
        src_id = src_person_id.split(":")[-1]
        target_id = target_person_id.split(":")[-1]

        super().__init__(
            src_person_id=src_id,
            target_person_id=target_id,
            relationship=relationship,
        )


def process_mapping_from_tsv_to_person_mapping(file_name):
    tsv_file_name = join(MAP_DIR, file_name)
    mapping_set_df = parse_sssom_table(file_path=tsv_file_name)
    ms = mapping_set_df.to_mapping_set()
    person_maps = [
        PersonMap(
            **{
                "src_person_id": item["subject_id"],
                "target_person_id": item["object_id"],
                "relationship": item["predicate_id"],
            }
        )
        for item in ms.mappings
        if item["predicate_id"] != "noMatch"
    ]
    return person_maps


def process_mappings_to_persons(person_maps):
    output_persons = []
    for rm in person_maps:

        s_id = rm.src_person_id
        o_id = rm.target_person_id
        person = Person(id=s_id)
        person_for_inverse = Person(id=o_id)

        relationship = rm.relationship
        if relationship == "skos:closeMatch":
            person.closeMatch = [o_id]
            person_for_inverse.closeMatch = [s_id]
        elif relationship == "skos:exactMatch":
            person.exactMatch = [o_id]
            person_for_inverse.exactMatch = [s_id]
        elif relationship == "skos:broadMatch":
            person.broadMatch = [o_id]
            person_for_inverse.narrowMatch = [s_id]
        elif relationship == "skos:narrowMatch":
            person.narrowMatch = [o_id]
            person_for_inverse.broadMatch = [s_id]
        elif relationship == "skos:relatedMatch":
            person.relatedMatch = [o_id]
            person_for_inverse.relatedMatch = [s_id]
        else:
            logger.info("Unparsable predicate_id: %s", relationship)

        output_persons.append(person)
        output_persons.append(person_for_inverse)

    return output_persons


def write_to_file(output_persons, output_file):
    with open(output_file, "+tw", encoding="utf-8") as output_file:
        print(YAMLDumper().dumps(PersonCollection(persons=output_persons)), file=output_file)
        output_file.close()


if __name__ == "__main__":
    logger.info(f"Processing mapping files in : %s", MAP_DIR)
    mapping_files = [
        file_name
        for file_name in listdir(MAP_DIR)
        if (file_name.endswith(".md") == False) and isfile(join(MAP_DIR, file_name))
    ]
    for file_name in mapping_files:
        output_file = DATA_DIR + Path(file_name).stem + "_from_tsv_data.yaml"
        rs = process_mapping_from_tsv_to_person_mapping(file_name)
        logger.info(f"Processed file: %s, %s valid entries", file_name, len(rs))
        output_persons = process_mappings_to_persons(rs)
        write_to_file(output_persons, output_file)

